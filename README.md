# Chasuite Interview Classification & Analysis

This repository contains the complete solution to the Chasuite NLP Competition, which focuses on analyzing professional sports interview transcripts and classifying them into predefined categories using state-of-the-art NLP techniques.

## ğŸ¯ Objective

Given a dataset of interview transcripts across sports contexts (e.g., NFL, NBA, NHL), the goal is to:

- Predict interview categories like "Game Strategy", "Post-Game Analysis", etc.
- Generate plausible interview responses based on category and question
- Visualize clusters of topics within the interviews
- Build a Streamlit dashboard to demo the system

---

## ğŸ§± Project Structurechasuite_exam/
â”‚
â”œâ”€â”€ data/                   # Raw and processed data
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ val.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ models/                 # Trained models and tokenizers
â”‚   â”œâ”€â”€ logistic_model.pkl
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â”œâ”€â”€ bert_model/
â”‚
â”œâ”€â”€ results/                # Outputs: predictions, figures, visualizations
â”‚   â”œâ”€â”€ submission.csv
â”‚   â”œâ”€â”€ results.json
â”‚   â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ text_generation/
â”‚
â”œâ”€â”€ streamlit/              # Streamlit app and UI components
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ components/
â”‚
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ text_generation.py
â”‚   â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ main.py                 # End-to-end driver script
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # Youâ€™re here
â””â”€â”€ AI_tool_declaration.txt # Declaration of AI tool usage



---

## ğŸ”§ Technologies Used

- **Python 3.9+**
- **Transformers (HuggingFace)** for BERT and GPT-2
- **scikit-learn** for classic ML models
- **NLTK** and **WordCloud** for text preprocessing and visualization
- **UMAP, t-SNE, KMeans** for topic clustering
- **Streamlit** for dashboard
- **Plotly** for interactive embeddings

---

## ğŸš€ Key Features

- âœ… Logistic Regression with TF-IDF and feature importance
- âœ… Fine-tuned BERT for multi-class classification
- âœ… GPT-2-based response generation
- âœ… UMAP-based topic clustering and visualization
- âœ… Ethical reflection on AI in journalism
- âœ… Streamlit app with full functionality

---

## ğŸ“ How to Run

### 1. Install Dependencies

```bash
pip install -r requirements.txt



Run the pipeline 

python main.py


Launch the StreamlitApp

streamlit run streamlit/app.py